{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data preprocessing and pipelines\n",
    "We explore the performance of several linear regression models on a real-world dataset, i.e. [MoneyBall](https://www.openml.org/d/41021). See the description on OpenML for more information. In short, this dataset captures performance data from baseball players. The regression task is to accurately predict the number of 'runs' each player can score, and understanding which are the most important factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import openml as oml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MoneyBall data from OpenML\n",
    "moneyball = oml.datasets.get_dataset(41021)\n",
    "# Get the pandas dataframe (default)\n",
    "X, y, _, attribute_names = moneyball.get_data(target=moneyball.default_target_attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exploratory analysis and visualization\n",
    "First, we visually explore the data by visualizing the value distribution and the interaction between every other feature in a scatter matrix. We use the target feature as the color variable to see which features are correlated with the target.\n",
    "\n",
    "For the plotting to work, however, we need to remove the categorical features (the first 2) and fill in the missing values. Let's find out which columns have missing values. This matches what we already saw on the OpenML page (https://www.openml.org/d/41021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(X).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first quick visualization, we will simply impute the missing values using the median. Removing all instances with missing values is not really an option since some features have consistent missing values: we would have to remove a lot of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values with sklearn and rebuild the dataframe\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_clean_array = imputer.fit_transform(X[attribute_names[2:]]) # skip the first 2 features\n",
    "# The imputer will return a numpy array. To plot it we make it a pandas dataframe again.\n",
    "X_clean = pd.DataFrame(X_clean_array, columns = attribute_names[2:]) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build the scatter matrix. We include the target column to see which features strongly correlate with the target, and also use the target value as the color to see which combinations of features correlate with the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise 1: Build a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function `build_pipeline` that does the following:\n",
    "- Impute missing values by replacing NaN's with the feature median for numerical features.\n",
    "- Encode the categorical features using OneHotEncoding.\n",
    "- If the attribute `scaling=True`, also scale the data using standard scaling.\n",
    "- Attach the given regression model to the end of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(regressor, numerical, categorical, scaling=False):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "def build_pipeline(regressor, categorical, scaling=False):\n",
    "    cat_pipe = make_pipeline(OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "    num_pipe = make_pipeline(SimpleImputer(strategy='mean'))\n",
    "    if scaling:\n",
    "        num_pipe.steps.insert(1,[\"scaler\", StandardScaler()]) \n",
    "    transform = make_column_transformer((cat_pipe, categorical), remainder=num_pipe)\n",
    "    # Give a name to the regressor so that we can tune it more easily\n",
    "    return Pipeline(steps=[('preprocess', transform), ('reg', regressor)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Test the pipeline\n",
    "Test the pipeline by evaluating linear regression (without scaling) on the dataset, using 5-fold cross-validation and $R^2$. Make sure to run it on the original dataset ('X'), not the manually cleaned version ('X_clean')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model solution\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "categorical = [\"Team\",\"League\"]\n",
    "regressor = LinearRegression()\n",
    "pipe = build_pipeline(LinearRegression(),categorical)\n",
    "scores = cross_val_score(pipe, X, y)\n",
    "print(\"Cross-validated R^2 score for {}: {:.2f}\".format(regressor.__class__.__name__, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: A first benchmark\n",
    "Evaluate the following algorithms in their default settings, both with and without scaling, and interpret the results:  \n",
    "- Linear regression\n",
    "- Ridge\n",
    "- Lasso\n",
    "- SVM (RBF)\n",
    "- RandomForests\n",
    "- GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model solution\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "models = [LinearRegression(), Ridge(), Lasso(), RandomForestRegressor(), GradientBoostingRegressor(), SVR()]\n",
    "for m in tqdm(models):\n",
    "    pipe = build_pipeline(m,categorical)\n",
    "    scores = cross_val_score(pipe, X, y)\n",
    "    print(\"R^2 score for {}: {:.2f}\".format(m.__class__.__name__, scores.mean()))\n",
    "    pipe = build_pipeline(m,categorical, scaling=True)\n",
    "    scores = cross_val_score(pipe, X, y)\n",
    "    print(\"R^2 score for {} (scaled): {:.2f}\".format(m.__class__.__name__, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise 4: Feature importance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
